<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>大数据2 - 合集 | Fred的知识库</title>
    <link>http://localhost:1313/collections/%E5%A4%A7%E6%95%B0%E6%8D%AE2/</link>
    <description>大数据2 - 合集 | Fred的知识库</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>330446875@qq.com (Fred)</managingEditor>
      <webMaster>330446875@qq.com (Fred)</webMaster><copyright>本站内容采用 CC BY-NC-SA 4.0 国际许可协议。</copyright><lastBuildDate>Tue, 23 Apr 2024 20:01:01 &#43;0800</lastBuildDate><atom:link href="http://localhost:1313/collections/%E5%A4%A7%E6%95%B0%E6%8D%AE2/" rel="self" type="application/rss+xml" /><item>
  <title>Hadoop概览</title>
  <link>http://localhost:1313/bigdata/hadoop/hadoop%E6%A6%82%E8%A7%88/</link>
  <pubDate>Tue, 23 Apr 2024 20:01:01 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>http://localhost:1313/bigdata/hadoop/hadoop%E6%A6%82%E8%A7%88/</guid>
  <description><![CDATA[<h1 id="hdfs" class="heading-element">
  <a href="#hdfs" class="heading-mark"></a>HDFS</h1><ol>
<li>HDFS概述</li>
</ol>
<p>Hadoop 分布式系统框架中，首要的基础功能就是文件系统，在 Hadoop 中使用 FileSystem 这个抽象类来表示我们的文件系统，这个抽象类下面有很多子实现类，究竟使用哪一种，需要看我们具体的实现类，在我们实际工作中，用到的最多的就是HDFS(分布式文件系统)以及LocalFileSystem(本地文件系统)了。</p>
<p>在现代的企业环境中，单机容量往往无法存储大量数据，需要跨机器存储。统一管理分布在集群上的文件系统称为分布式文件系统。</p>
<p>HDFS（Hadoop  Distributed  File  System）是 Hadoop 项目的一个子项目。是 Hadoop 的核心组件之一，  Hadoop 非常适于存储大型数据 (比如 TB 和 PB)，其就是使用 HDFS 作为存储系统. HDFS 使用多台计算机存储文件，并且提供统一的访问接口，像是访问一个普通文件系统一样使用分布式文件系统。</p>
<p><a class="lightgallery" href="https://files.catbox.moe/6l0xa2.png?size=large" data-thumbnail="https://files.catbox.moe/6l0xa2.png?size=small" data-sub-html="<h2>6l0xa2.png</h2>"><img loading="lazy" src="https://files.catbox.moe/6l0xa2.png" alt="6l0xa2.png" srcset="https://files.catbox.moe/6l0xa2.png?size=small, https://files.catbox.moe/6l0xa2.png?size=medium 1.5x, https://files.catbox.moe/6l0xa2.png?size=large 2x" data-title="6l0xa2.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<ol start="2">
<li>HDFS架构</li>
</ol>
<p><a class="lightgallery" href="https://files.catbox.moe/7srz72.png?size=large" data-thumbnail="https://files.catbox.moe/7srz72.png?size=small" data-sub-html="<h2>7srz72.png</h2>"><img loading="lazy" src="https://files.catbox.moe/7srz72.png" alt="7srz72.png" srcset="https://files.catbox.moe/7srz72.png?size=small, https://files.catbox.moe/7srz72.png?size=medium 1.5x, https://files.catbox.moe/7srz72.png?size=large 2x" data-title="7srz72.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>HDFS是一个主/从（Mater/Slave）体系结构，由三部分组成： NameNode 和 DataNode 以及 SecondaryNamenode：</p>
<p>● NameNode 负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。<br>
● DataNode 负责管理用户的文件数据块，每一个数据块都可以在多个 DataNode 上存储多个副本，默认为3个。<br>
● Secondary NameNode 用来监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。最主要作用是辅助 NameNode 管理元数据信息。</p>
<p><a class="lightgallery" href="https://files.catbox.moe/76lm4z.png?size=large" data-thumbnail="https://files.catbox.moe/76lm4z.png?size=small" data-sub-html="<h2>76lm4z.png</h2>"><img loading="lazy" src="https://files.catbox.moe/76lm4z.png" alt="76lm4z.png" srcset="https://files.catbox.moe/76lm4z.png?size=small, https://files.catbox.moe/76lm4z.png?size=medium 1.5x, https://files.catbox.moe/76lm4z.png?size=large 2x" data-title="76lm4z.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<ol start="3">
<li>HDFS的特性</li>
</ol>
<p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间目录树来定位文件；</p>
<p>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p>
<ol>
<li>master/slave 架构（主从架构）</li>
</ol>
<p>HDFS 采用 master/slave 架构。一般一个 HDFS 集群是有一个 Namenode 和一定数目的 Datanode 组成。Namenode 是 HDFS 集群主节点，Datanode 是 HDFS 集群从节点，两种角色各司其职，共同协调完成分布式的文件存储服务。</p>
<ol start="2">
<li>分块存储</li>
</ol>
<p>HDFS 中的文件在物理上是分块存储（block）的，块的大小可以通过配置参数来规定，默认大小在 hadoop2.x 版本中是 128M。</p>
<ol start="3">
<li>名字空间（NameSpace）</li>
</ol>
<p>HDFS 支持传统的层次型文件组织结构。用户或者应用程序可以创建目录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数现有的文件系统类似：用户可以创建、删除、移动或重命名文件。 Namenode 负责维护文件系统的名字空间，任何对文件系统名字空间或属性的修改都将被 Namenode 记录下来。 HDFS 会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data。</p>
<ol start="4">
<li>NameNode 元数据管理</li>
</ol>
<p>我们把目录结构及文件分块位置信息叫做元数据。NameNode 负责维护整个 HDFS 文件系统的目录树结构，以及每一个文件所对应的 block 块信息（block 的 id，及所在的 DataNode 服务器）。</p>
<ol start="5">
<li>DataNode 数据存储</li>
</ol>
<p>文件的各个 block 的具体存储管理由 DataNode 节点承担。每一个 block 都可以在多个 DataNode 上。DataNode 需要定时向 NameNode 汇报自己持有的 block 信息。 存储多个副本（副本数量也可以通过参数设置 dfs.replication，默认是 3）</p>
<ol start="6">
<li>副本机制</li>
</ol>
<p>为了容错，文件的所有 block 都会有副本。每个文件的 block 大小和副本系数都是可配置的。应用程序可以指定某个文件的副本数目。副本系数可以在文件创建的时候指定，也可以在之后改变。</p>
<ol start="7">
<li>一次写入，多次读出</li>
</ol>
<p>HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的修改。 正因为如此，HDFS 适合用来做大数据分析的底层存储服务，并不适合用来做网盘等应用，因为修改不方便，延迟大，网络开销大，成本太高。</p>
]]></description>
</item>
<item>
  <title>Hadoop的简介</title>
  <link>http://localhost:1313/posts/hadoop%E7%AE%80%E4%BB%8B/</link>
  <pubDate>Mon, 20 Feb 2023 20:14:22 &#43;0800</pubDate>
  <author>Fred</author>
  <guid>http://localhost:1313/posts/hadoop%E7%AE%80%E4%BB%8B/</guid>
  <description><![CDATA[<h2 id="目的" class="heading-element">
  <a href="#%e7%9b%ae%e7%9a%84" class="heading-mark"></a>目的</h2><p>这篇文档的目的是帮助你快速完成单机上的Hadoop安装与使用以便你对Hadoop分布式文件系统(HDFS)和Map-Reduce框架有所体会，比如在HDFS上运行示例程序或简单作业等。</p>
<h2 id="先决条件" class="heading-element">
  <a href="#%e5%85%88%e5%86%b3%e6%9d%a1%e4%bb%b6" class="heading-mark"></a>先决条件</h2><p>支持平台
GNU/Linux是产品开发和运行的平台。 Hadoop已在有2000个节点的GNU/Linux主机组成的集群系统上得到验证。
Win32平台是作为开发平台支持的。由于分布式操作尚未在Win32平台上充分测试，所以还不作为一个生产平台被支持。
所需软件
Linux和Windows所需软件包括:</p>
<p>JavaTM1.5.x，必须安装，建议选择Sun公司发行的Java版本。
ssh 必须安装并且保证 sshd一直运行，以便用Hadoop 脚本管理远端Hadoop守护进程。
Windows下的附加软件需求</p>
<p>Cygwin - 提供上述软件之外的shell支持。</p>
<h2 id="安装软件" class="heading-element">
  <a href="#%e5%ae%89%e8%a3%85%e8%bd%af%e4%bb%b6" class="heading-mark"></a>安装软件</h2><p>如果你的集群尚未安装所需软件，你得首先安装它们。</p>
<p>以Ubuntu Linux为例:</p>
<p>$ sudo apt-get install ssh
$ sudo apt-get install rsync</p>
<p>在Windows平台上，如果安装cygwin时未安装全部所需软件，则需启动cyqwin安装管理器安装如下软件包：</p>
<p>openssh - Net 类</p>
]]></description>
</item>
</channel>
</rss>
